{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"Le Back-end de la plateforme BotsCity.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"g57braNSSrjV","colab_type":"text"},"source":["Si vous venez de confronter un Rest API pour la première fois, veuillez vous référer à ces articles qui présentent les concepts utilisés dans ce projet:\n","- Serveur HTTP: https://www.freecodecamp.org/news/http-and-everything-you-need-to-know-about-it/\n","- API Rest: https://code.tutsplus.com/tutorials/a-beginners-guide-to-http-and-rest--net-16340\n","- Documentation de la bibliotheque flask: https://flask.palletsprojects.com/en/1.1.x/\n","\n","# La première étape consiste à installer toutes les dépendances\n","\n","- tensorflow\n","- flask\n","- flask-mail\n","- bs4\n","\n","## PS: Avant de commencer, placez ce Notebook dans le même répertoire avec ces fichiers:\n","- Chatbots.json\n","- COVID_MINI_Q.txt\n","- help.txt\n","- COVID_Finale_24-06.h1\n","- Screenshot_12.png\n","- diagramme.png\n"]},{"cell_type":"code","metadata":{"id":"RVMNOho5SrjZ","colab_type":"code","colab":{}},"source":["!pip install tensorflow flask flask-mail bs4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zjm4BWjZSrjl","colab_type":"code","colab":{}},"source":["from abc import ABC\n","from flask import Flask, request, jsonify\n","from tensorflow.keras.models import load_model\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","import requests\n","from bs4 import BeautifulSoup"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NVss1vruSrj0","colab_type":"text"},"source":["# Nous définissons les fonctions que nous utilisons pour le traitement de texte\n","pour plus de détail sur les fonctions de prétraitement, voir les notebooks de la création des modèles"]},{"cell_type":"code","metadata":{"id":"M7IqzYxuSrj1","colab_type":"code","colab":{}},"source":["def pad(x, length=None):\n","    if length is None:\n","        length = max([len(sentence) for sentence in x])\n","        print('Length Max: {}'.format(length))\n","        print()\n","    return pad_sequences(x, maxlen=length, padding='post')\n","\n","\n","def preprocess(Q, A):\n","    preprocess_Q, Q_tk = tokenize(Q)\n","    preprocess_A, A_tk = tokenize(A)\n","\n","    preprocess_Q = pad(preprocess_Q)\n","    preprocess_A = pad(preprocess_A)\n","\n","    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n","    preprocess_A = preprocess_A.reshape(*preprocess_A.shape, 1)\n","\n","    return preprocess_Q, preprocess_A, Q_tk, A_tk\n","\n","\n","def toPredectible(qes, tok, shape):\n","    tt = []\n","    for q in qes.split(' '):\n","        if q in tok.word_index:\n","            tt.append(tok.word_index[q])\n","        else:\n","            tt.append(0)\n","    return pad([tt], shape)\n","\n","\n","def tokenize(x):\n","    tokenizer = Tokenizer(char_level=False, filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n","    tokenizer.fit_on_texts(x)\n","\n","    return tokenizer.texts_to_sequences(x), tokenizer\n","\n","\n","def logits_to_text(logits, tokenizer):\n","    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n","    index_to_words[0] = '<PAD>'\n","    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BZ_ZMzDESrj_","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"HICUBt8mSrkA","colab_type":"text"},"source":["# Diagramme de classe\n","\n","![title](diagramme.png)\n","\n","\n","# Ici nous définissons les classes citées dans le diagramme des classes dans le rapport"]},{"cell_type":"markdown","metadata":{"id":"cgqnLZYKSrkB","colab_type":"text"},"source":["### La Classe abstraite Chatbot:\n","cette class a comme attributs : \n","- **modelPath** :  chemin du fichier .h1 où le modele est sauvegardé\n","- **model** : keras.model\n","- **question** : le chemin du fichier qui contient toutes les questions le chatbot utilisées pour l'entrainement du chatbot\n","- **Q_tokenizer** : le dictionnaire des mots avec les indices\n","- **max_Q_sequence_length** : la taille maximale de la question ( nb de mots possible )\n","\n","et contient les signatures des fonctions\n","- **Load_corpus** : pour construire le dictionnaire\n","- **get_answer** :  Predict la reponse et la retourne \n","\n","et les fonctions: \n","- **load**: pour charger le modele\n","- **get_status** : pour verifier si le modele est charger\n"]},{"cell_type":"code","metadata":{"id":"OYxQPt1NSrkE","colab_type":"code","colab":{}},"source":["class Chatbot(ABC):\n","    model = None\n","    question = None\n","    preproc_Q = None\n","    Q_tokenizer = None\n","    max_Q_sequence_length = None\n","    Q_vocab_size = None\n","    status = False\n","    \n","    #methode pour charger le modele\n","    def load(self):\n","        self.model = load_model(self.modelPath)\n","        self.load_corpus()\n","        self.status = True\n","        return True\n","    \n","    def load_corpus(self):\n","        pass\n","    \n","    #methode abstraite qui prend une question et renvoie sa reponse\n","    def get_answer(self, query):\n","        pass\n","    \n","    #methode pour verifier si le modele est charger\n","    def get_status(self):\n","        return self.status"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XWnHjAv5SrkS","colab_type":"text"},"source":["#### La classe Seq2SeqChatbot \n","cette Classe qui herite de la classe Chatbot pour les chatbot de **Sequence to Sequence**:\n","elle ajoute comme attributs:\n","- **A_tokenizer** : le dictionnaire des mots des Reponses avec les indices\n","- **max_A_sequence_length** : la taille maximale de la reponse ( nb de mots possibles)\n","\n","et definit ca propre version pour les fonctions:\n","- **__init__** : le constructeur\n","- **load_corpus** \n","- **get_answer**"]},{"cell_type":"code","metadata":{"id":"OZERD5LlSrkU","colab_type":"code","colab":{}},"source":["class Seq2SeqChatbot(Chatbot):\n","    preproc_A = None\n","    A_tokenizer = None\n","    max_A_sequence_length = None\n","    A_vocab_size = None\n","    \n","    #Constructeur\n","    def __init__(self, name, model_path, ques, res):\n","        self.modelPath = model_path\n","        self.name = name\n","        self.status = False\n","        self.quesP = ques\n","        self.resP = res\n","        \n","    def load_corpus(self):\n","        file = open(self.resP, 'rt', encoding='utf-8')\n","        text = file.read()\n","        A_data = text.split(\"\\n\")\n","        help = A_data[0].replace('\\ufeff', '')\n","        del A_data[0]\n","        A_data.insert(0, help)\n","        file = open(self.quesP, 'rt', encoding='utf-8')\n","        text = file.read()\n","        Q_data = text.split(\"\\n\")\n","        help = Q_data[0].replace('\\ufeff', '')\n","        del Q_data[0]\n","        Q_data.insert(0, help)\n","\n","        # Prétraitement\n","        self.preproc_Q, self.preproc_A, self.Q_tokenizer, self.A_tokenizer = preprocess(Q_data, A_data)\n","        self.max_Q_sequence_length = self.preproc_A.shape[1]\n","        self.max_A_sequence_length = self.preproc_Q.shape[1]\n","\n","        self.Q_vocab_size = len(self.Q_tokenizer.word_index)\n","        self.A_vocab_size = len(self.A_tokenizer.word_index)\n","        \n","    def get_answer(self, query):\n","        question = toPredectible(query, self.Q_tokenizer, self.max_Q_sequence_length)\n","        print(question)\n","        return logits_to_text(self.model.predict(question)[0], self.A_tokenizer).replace('<PAD> ', '').replace('<PAD>', '').replace('<start> ', '').replace('<end>','')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DnN_4o4fSrkd","colab_type":"text"},"source":["#### La classe  ClassificationChatbot \n","cette classe qui hérite de la classe Chatbot est pour les chatbots qui utilisent la classification pour répondre, elle ajoute comme attributs:\n","\n","- **h_data**: La liste des reponses\n","\n","et definit sa propre version pour les fonctions:\n","\n","- **load_corpus** : construit seulement un dictionnaire des mots pour les questions, les réponses sont déjà prés et seront charges dans h_data\n","- **get_answer** : predict l'indice de la réponse à l'aide du modèle et retourne la réponse (h_data[indice])"]},{"cell_type":"code","metadata":{"id":"4ReM3iz6Srke","colab_type":"code","colab":{}},"source":["class ClassificationChatbot(Chatbot):\n","    \n","    h_data = None\n","\n","    def __init__(self, name, model_path, ques, help):\n","        self.modelPath = model_path\n","        self.name = name\n","        self.status = False\n","        self.quesP = ques\n","        self.help = help\n","\n","    def load_corpus(self):\n","        file = open(self.quesP, 'r', encoding='utf-8')\n","        text = file.read()\n","        Q_data = text.split(\"\\n\")\n","        help = Q_data[0].replace('\\ufeff', '')\n","        del Q_data[0]\n","        Q_data.insert(0, help)\n","\n","        file = open(self.help, 'r', encoding='utf-8')\n","        text = file.read()\n","        self.h_data = text.split(\"\\n\")\n","        help = self.h_data[0].replace('\\ufeff', '')\n","        del self.h_data[0]\n","        self.h_data.insert(0, help)\n","\n","        self.preproc_Q, self.Q_tokenizer = self.preprocess(Q_data)\n","        self.max_Q_sequence_length = self.preproc_Q.shape[1]\n","        self.Q_vocab_size = len(self.Q_tokenizer.word_index) + 1\n","\n","    def preprocess(self, Q_data):\n","        preprocess_Q, Q_tk = tokenize(Q_data)\n","        preprocess_Q = pad(preprocess_Q)\n","        return preprocess_Q, Q_tk\n","\n","    def get_answer(self, query):\n","        question = toPredectible(query, self.Q_tokenizer, self.max_Q_sequence_length)\n","        a = self.model.predict(np.array(question))[0]\n","        a = list(a)\n","        id = a.index(max(a))\n","        \n","        #on detecte les classes ou le chatbot doit chercher la reponse\n","        if id == 80:\n","            url = 'https://covid.hespress.com/'\n","            resp = requests.get(url=url)\n","            data = BeautifulSoup(resp.text)\n","            cases = [d.string for d in data.find_all('h4')]\n","            totalcases = cases[0]\n","            noncovid = cases[1]\n","            healed = cases[2]\n","            deaths = cases[3]\n","            recovring = cases[4]\n","            plus = data.find_all('span')\n","            totalcasesplus = str(plus[2]).split('</i>')[1].replace('</span>', '')\n","            response = 'تم تسجيل ' + totalcasesplus + ' حالة جديدة, حيت بلغ العدد الإجمالي للحالات ' + totalcases\n","            return response\n","        return self.h_data[id]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zrI8w2aOSrkk","colab_type":"text"},"source":["###  Le Gestionnaire\n","\n","    Dans l'application on a utilisé une base de données MongoDB pour sauvegarder les informations relatives à chaque chatbot, mais dans cette explication, on a remplacé ça avec un fichier Json \"Chatbots.json\" qui est de cette structure:\n","```{\n","    \"chatbots\": [\n","        {\n","            \"intitule\": \"Covid\",\n","            \"modelPath\": \"covid.h1\",\n","            \"QuestionPath\": \"covid_ques.txt\",\n","            \"ResponsePath\": \"covide_response.txt\",\n","            \"type\": \"classification\",\n","            \"Propositions\": [\n","                ...\n","            ]\n","        },\n","        ...\n","    ]\n","}```"]},{"cell_type":"code","metadata":{"id":"sAqYKCVFSrkl","colab_type":"code","colab":{}},"source":["class Gestion:\n","    DataBase = 'Chatbots.json'\n","    bots_objects = {}\n","\n","    def __init__(self):\n","        with open(self.DataBase, 'r') as myfile:\n","            data=myfile.read()\n","        bots = json.loads(data)[\"chatbots\"]\n","        \n","        #La creation des instances des chatbots selon le type (Seq2Seq ou Classification)\n","        for bot in bots:\n","            if bot['type'] == 'Seq2Seq':\n","                self.bots_objects[bot[\"intitule\"]] = Seq2SeqChatbot(bot[\"intitule\"],\n","                                                         bot[\"modelName\"],\n","                                                         bot[\"questionsPath\"],\n","                                                         bot[\"responsesPath\"])\n","            elif bot['type'] == 'classification':\n","                self.bots_objects[bot[\"intitule\"]] = ClassificationChatbot(bot[\"intitule\"],\n","                                                                   bot[\"modelName\"],\n","                                                                   bot[\"questionsPath\"],\n","                                                                   bot[\"responsesPath\"])\n","\n","                \n","    def load_bot(self, name):\n","        if self.bots_objects[name].get_status():\n","            return True\n","        else:\n","            return self.bots_objects[name].load()\n","\n","    def get_answer(self, name, query):\n","        if self.bots_objects[name].get_status():\n","            return self.bots_objects[name].get_answer(query)\n","        else:\n","            return 'إمتضر قليلا من فضلك'\n","\n","    #Creer une liste des chatbots pour l'utilisateur\n","    def list(self):\n","        lbot = []\n","        for key in self.bots_objects:\n","            lbot.append({\n","                \"name\": key,\n","                \"uri\": \"https://picsum.photos/200/300\",\n","                \"color\": \"red\",\n","                \"describtion\": \"أنا صديقكم الألي\"\n","            })\n","        return lbot\n","\n","    def add_proposition(self, app, name, question, response):\n","        pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jMYKj5uMSrkr","colab_type":"text"},"source":["# La création du flask Api a l'aide de la bibliothèque flask"]},{"cell_type":"code","metadata":{"id":"xpmS27HeSrks","colab_type":"code","colab":{}},"source":["# Creer l'instance du serveur flask\n","import json\n","app = Flask('__main__')\n","\n","#Creer l'instance du gestionnaire\n","gst = Gestion()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BCKjptrdSrkz","colab_type":"text"},"source":["### La definission des routes pour chaque service\n","\n","![title](Screenshot_12.png)"]},{"cell_type":"markdown","metadata":{"id":"bSSHJ68zSrk0","colab_type":"text"},"source":["**1:** Ajouter un nouveau listner sur la requet HTTP de type GET dont l'url commence par /ask/**name** et name represente une valeur string qui contient le nom du Chatbot et un parametre query qui contient la question.\n","    \n","**2:** la fonction prend en parametre le nom du Chatbot.\n","    \n","**3:** Appel vers le service pour recuperation de la reponse selon les valeurs des parameteres envoyés par le client au niveau de la requete HTTP.\n","    \n","**4:** La réponse est retournée en format objet pour l'envoyer au client il faudra la transformer en format json ce qui possible et simple par la fonction jsonify() fournie par les Lib standard de python\n"]},{"cell_type":"code","metadata":{"id":"bpZKjUq2Srk2","colab_type":"code","colab":{}},"source":["@app.route('/ask/<name>', methods=['GET'])\n","def hello_world(name):\n","    answer = gst.get_answer(name, request.args.get('query'))\n","    return jsonify(ans=answer)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rwKefwFJSrk7","colab_type":"text"},"source":["1: Ajouter un nouveau listner sur la requet HTTP de type GET dont l'url commence par /load/**name** et name represente une valeur string qui contient le nom du Chatbot que l'utilisateur veut interoger par la suite.\n","\n","2: la fonction prend en parametre le nom du Chatbot.\n","\n","3: Appel vers le gestionnaire pour charger le chatbot qui porte le nom indique dans la variable name\n"]},{"cell_type":"code","metadata":{"id":"DSLA3Q5XSrk8","colab_type":"code","colab":{}},"source":["@app.route('/load/<name>', methods=['GET'])\n","def load_bot(name):\n","    gst.load_bot(name)\n","    return jsonify(ans=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PgkhUrjOSrlD","colab_type":"code","colab":{}},"source":["@app.route('/list', methods=['Get'])\n","def list_of_bots():\n","    lbot = gst.list()\n","    return jsonify(lbot)\n","\n","@app.route('/propose/<name>', methods=['Post'])\n","def propose(name):\n","    gst.add_proposition(app, name, request.args.get('question'), request.args.get('response'))\n","    return jsonify(ans=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BV9zM-voSrlJ","colab_type":"text"},"source":["### Lancer le serveur http sur le port 5000"]},{"cell_type":"code","metadata":{"id":"QyzvoU_kSrlJ","colab_type":"code","colab":{}},"source":["app.run()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yfjIiGJMSrlP","colab_type":"text"},"source":["# Exemples \n","\n","1) pour avoir la liste des chatbots disponible"]},{"cell_type":"code","metadata":{"id":"Btb3L65_SrlP","colab_type":"code","colab":{}},"source":["!curl -v http://localhost:5000/list"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Jbgy9NjSrlV","colab_type":"text"},"source":["2) Avant de poser une question, il faut envoyer une requête pour charger le modèle"]},{"cell_type":"code","metadata":{"id":"LSBCIuhSSrlW","colab_type":"code","colab":{}},"source":["!curl -v http://localhost:5000/load/Covid"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a-hRYL3HSrla","colab_type":"text"},"source":["3) pour poser une question"]},{"cell_type":"code","metadata":{"id":"0Otj3y_pSrlb","colab_type":"code","colab":{}},"source":["!curl -v http://localhost:5000/ask/Covid?query=مستجدات كورونا اليوم"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RaxgNZMYSrlf","colab_type":"text"},"source":["## Installer l'application attachée à ce projet (Bots City.apk) pour tester le chatbot dans votre téléphone"]}]}